Hello there,

I observed the data and concluded that it was totally discreet, categorical, to be exact.
I mean the data can be and should be converted to categorical data for better estimation.

I decided to use the Naive Bayes approach to estimate the likelihood of 'Loan Approval'.
Hence, I went ahead with the assumption that all the feature vectors are independent of each other and have the same weightage in decision making.

Therefore, I wrote the code following the Bayes Theorem ie.

Posterior probability (Likelihood) of event A given B is directly proportional to the Likelihood of B given A times the Prior probability of A.

Then, I calculated the class conditional density of a features vector by multiplying the class conditional densities of individual features.

During this calculation, I observed that I could adjust the weightage of the features.
After some research on Google I found out liability matters the most and then comes the payment history (credit/debit).
Hence, I tried different weights for the two and reached the optima.
Also, I updated the missing data points to the corresponding feature's mode.

Finally, I calculated the answer and publish the results to 'sub.csv'
